{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a440374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. 환경 설정 ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib  # 한글 깨짐 방지\n",
    "import seaborn as sns\n",
    "\n",
    "# 머신러닝 관련 라이브러리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# 희소행렬 결합\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ru690jlt1pd",
   "source": "## 0. 환경 설정\n\n### 📚 라이브러리 설명\n\n**데이터 처리:**\n- `pandas`, `numpy`: 데이터 조작 및 수치 계산\n\n**시각화:**\n- `matplotlib`, `seaborn`: 그래프 생성\n- `koreanize_matplotlib`: 한글 폰트 설정\n\n**머신러닝 (scikit-learn):**\n- `train_test_split`: 데이터를 train/test로 분할\n- `StandardScaler`: 숫자 피처 표준화 (평균 0, 분산 1)\n- `TfidfVectorizer`: 텍스트를 숫자 벡터로 변환\n- `LinearRegression`, `RandomForestRegressor`, `LGBMRegressor`: 회귀 모델\n- `r2_score`, `mean_squared_error`: 성능 평가 지표\n\n**기타:**\n- `WordCloud`: 단어 구름 시각화\n- `scipy.sparse`: 희소 행렬 (메모리 효율적인 텍스트 표현)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "0bvr54l8a0od",
   "source": "# 🤖 AIOE 머신러닝 모델링\n\n이 노트북은 02번 EDA에서 준비한 데이터를 기반으로 **머신러닝 모델을 구축**하는 단계입니다.\n\n---\n\n## 🎯 모델링의 목적\n\n**핵심 질문:**\n> AIOE 점수와 고용 규모를 알면, 직업의 평균 임금을 예측할 수 있는가?\n\n### 왜 이 모델이 필요한가?\n\n**1. 이론 검증:**\n- 02번 EDA에서 AIOE와 임금의 양의 상관관계 발견\n- 이제 **실제로 예측 가능한 수준**인지 확인\n- Felten et al. (2023) 논문 결과 재현\n\n**2. 실용적 가치:**\n- 새로운 직업의 AIOE 계산 시 예상 임금 추정\n- 정책 입안자: AI 영향 분석 → 임금 영향 예측\n- 개인: 직업 선택 시 AI 영향도와 예상 임금 고려\n\n**3. 학습 목적:**\n- 다양한 머신러닝 모델 비교\n- 숫자 + 텍스트 피처 결합 실습\n- 모델 성능 평가 및 해석\n\n---\n\n## 📊 모델링 전략\n\n### 예측 문제 정의\n\n**예측 모델:**\n```\n독립변수 (X): AIOE, Employment, Description (텍스트)\n종속변수 (y): Mean_Wage (연평균 임금)\n```\n\n**모델 유형:** 회귀 (Regression)\n- 임금은 연속형 변수 → 회귀 문제\n\n### 실험 설계\n\n| 실험 | 피처 구성 | 목적 |\n|------|----------|------|\n| **Exp 1** | AIOE + Employment (숫자만) | 기본 성능 확인 |\n| **Exp 2** | AIOE + Employment + Description (텍스트 추가) | 텍스트가 성능 향상시키는가? |\n\n### 사용할 모델\n\n| 모델 | 특징 | 장점 | 단점 |\n|------|------|------|------|\n| **Linear Regression** | 선형 관계 가정 | 해석 쉬움, 빠름 | 비선형 관계 포착 못함 |\n| **Random Forest** | 의사결정나무 앙상블 | 비선형 OK, 피처 중요도 | 느림, 과적합 위험 |\n| **LightGBM** | Gradient Boosting | 고성능, 빠름 | 하이퍼파라미터 튜닝 필요 |\n\n### 평가 지표\n\n- **R² (결정계수)**: 모델이 분산의 몇 %를 설명하는가 (0~1, 높을수록 좋음)\n- **RMSE (평균 제곱근 오차)**: 예측 오차의 평균 (낮을수록 좋음, 단위: 달러)\n\n---\n\n## 🔗 이전 노트북과의 연결\n\n**01번 (전처리):**\n- AIOE 계산, OEWS 데이터 병합\n- `job_aioe_processed.csv` 생성\n\n**02번 (EDA):**\n- 완전한 데이터만 선택 (747개 직업)\n- 로그 변환 변수 생성\n- 상관관계 분석 → AIOE vs Mean_Wage 양의 상관\n- `job_aioe_for_modeling.csv` 생성\n\n**03번 (모델링):**\n- 02번 데이터 로드\n- 머신러닝 모델 학습 및 평가\n- 예측 성능 검증",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95c7bc",
   "metadata": {},
   "outputs": [],
   "source": "# 데이터 로드\ndf = pd.read_csv(\"../datas/processed/job_aioe_for_modeling.csv\")\n\nprint(\"✅ 데이터 로드 완료\")\nprint(f\"데이터 크기: {df.shape}\")\nprint(f\"\\n컬럼 목록:\")\nprint(df.columns.tolist())\nprint(f\"\\n상위 5개 행:\")\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "1vo6avf5l7a",
   "source": "## 1. 데이터 로드\n\n### 📥 모델링용 데이터 확인\n\n02번 노트북에서 생성한 `job_aioe_for_modeling.csv`를 로드합니다.\n\n**이 데이터의 특징:**\n- 747개 직업 (완전한 데이터만)\n- AIOE, Employment, Mean_Wage (원본 값)\n- Employment_log, Mean_Wage_log (로그 변환 값)\n- Description (직무 설명 텍스트)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd911ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description 길이(단어 수) 분포\n",
    "df['desc_length'] = df['Description'].fillna(\"\").apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['desc_length'], bins=30, kde=True)\n",
    "plt.title(\"직무 설명(Description) 길이 분포\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8h5eb6blrj9",
   "source": "## 2. 텍스트 데이터 탐색\n\n### 📝 Description (직무 설명) 분석\n\n텍스트 피처를 모델에 사용하기 전에, 먼저 **텍스트의 특성을 파악**합니다.\n\n**왜 Description을 사용하는가?**\n- 직무 설명에는 필요한 능력, 책임, 복잡도 등이 포함\n- 복잡한 직무 → 긴 설명, 전문 용어 많음 → 높은 임금 예상\n- 단순한 직무 → 짧은 설명, 일반 용어 → 낮은 임금 예상\n\n**탐색 내용:**\n1. 설명 길이 분포 (단어 수)\n2. 자주 등장하는 단어 (빈도)\n3. 워드클라우드 (시각화)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfff54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 20개 단어 빈도\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", max_features=20)\n",
    "word_counts = vectorizer.fit_transform(df['Description'].fillna(\"\"))\n",
    "\n",
    "word_freq = pd.DataFrame({\n",
    "    \"word\": vectorizer.get_feature_names_out(),\n",
    "    \"count\": word_counts.toarray().sum(axis=0)\n",
    "}).sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"count\", y=\"word\", data=word_freq)\n",
    "plt.title(\"Description 상위 20개 단어 빈도\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드클라우드\n",
    "text = \" \".join(df['Description'].dropna())\n",
    "wc = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"직무 설명 워드클라우드\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f08772",
   "metadata": {},
   "outputs": [],
   "source": "## 3. 피처와 타겟 정의\n\n### 🎯 예측 모델 설정\n\n**독립변수 (X) - 예측에 사용할 정보:**\n- `AIOE`: AI 직업 노출도 점수\n- `Employment_log`: 고용 규모 (로그 변환)\n- `Description`: 직무 설명 텍스트 (나중에 추가)\n\n**종속변수 (y) - 예측하려는 값:**\n- `Mean_Wage_log`: 평균 임금 (로그 변환)\n\n### 💡 왜 로그 변환을 사용하는가?\n\n02번 EDA에서 확인했듯이:\n- Employment와 Mean_Wage는 **극단적으로 치우친 분포**\n- 로그 변환 후 정규분포에 가까워짐\n- **모델 성능 향상** 기대\n\n**예측 후 역변환:**\n```python\ny_pred_log = model.predict(X)\ny_pred_original = np.expm1(y_pred_log)  # 원래 스케일로 복원\n```"
  },
  {
   "cell_type": "code",
   "id": "qa8r0f4sqz9",
   "source": "# 숫자형 피처 (로그 변환 사용!)\nX_num_raw = df[['AIOE', 'Employment_log']].copy()\n\n# 타겟 변수 (로그 변환 사용!)\ny = df['Mean_Wage_log'].copy()\n\n# Description 텍스트 (나중에 벡터화)\ndescriptions = df['Description'].fillna(\"\")\n\nprint(\"✅ 피처와 타겟 정의 완료\")\nprint(f\"숫자 피처 shape: {X_num_raw.shape}\")\nprint(f\"타겟 shape: {y.shape}\")\nprint(f\"Description 개수: {len(descriptions)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732cd6a",
   "metadata": {},
   "outputs": [],
   "source": "## 4. 데이터 분할 (Train/Test Split)\n\n### ⚠️ 중요: 데이터 누수 방지!\n\n**올바른 순서:**\n1. **먼저** train/test 분할\n2. **그 다음** train 데이터로 Scaler와 Vectorizer를 fit\n3. train과 test를 각각 transform\n\n**잘못된 순서 (데이터 누수):**\n```python\n# ❌ 잘못된 예\nscaler.fit(전체_데이터)  # 테스트 데이터 정보 누수!\nX_train, X_test = train_test_split(...)\n```\n\n**왜 문제인가?**\n- Scaler가 test 데이터의 평균/분산을 학습\n- 실전에서는 불가능한 정보 활용\n- 모델 성능이 과대평가됨\n\n### 📊 분할 비율\n\n- **Train**: 80% (모델 학습용)\n- **Test**: 20% (성능 평가용)\n- `random_state=42`: 재현 가능하도록 고정"
  },
  {
   "cell_type": "code",
   "id": "ga87bdkylu5",
   "source": "# 데이터 분할 (전체 데이터를 train/test로 나눔)\nfrom sklearn.model_selection import train_test_split\n\n# 숫자 피처 분할\nX_num_train_raw, X_num_test_raw, y_train, y_test = train_test_split(\n    X_num_raw, y, test_size=0.2, random_state=42\n)\n\n# Description 분할 (같은 인덱스로)\ndesc_train, desc_test = train_test_split(\n    descriptions, test_size=0.2, random_state=42\n)\n\nprint(\"✅ 데이터 분할 완료\")\nprint(f\"Train 크기: {X_num_train_raw.shape[0]} ({X_num_train_raw.shape[0]/len(df)*100:.1f}%)\")\nprint(f\"Test 크기: {X_num_test_raw.shape[0]} ({X_num_test_raw.shape[0]/len(df)*100:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492dac0b",
   "metadata": {},
   "outputs": [],
   "source": "## 5. 피처 전처리\n\n### 5-1. 숫자 피처 스케일링\n\n**StandardScaler란?**\n- 각 피처를 **평균 0, 분산 1**로 변환\n- 공식: `(x - mean) / std`\n\n**왜 스케일링이 필요한가?**\n- AIOE는 2~5 범위, Employment_log는 5~17 범위\n- 범위가 다르면 큰 값의 피처가 모델에 과도한 영향\n- Linear Regression은 스케일링 필수\n\n**올바른 방법:**\n1. Train 데이터로 평균/표준편차 계산 (fit)\n2. Train과 Test 모두에 같은 기준으로 변환 (transform)"
  },
  {
   "cell_type": "code",
   "id": "64bd0as31o2",
   "source": "# 숫자 피처 스케일링\nscaler = StandardScaler()\n\n# Train 데이터로 fit (평균, 표준편차 학습)\nX_num_train = scaler.fit_transform(X_num_train_raw)\n\n# Test 데이터는 transform만 (train의 평균/표준편차 사용)\nX_num_test = scaler.transform(X_num_test_raw)\n\nprint(\"✅ 숫자 피처 스케일링 완료\")\nprint(f\"Train 평균: {X_num_train.mean(axis=0)}\")  # 거의 0\nprint(f\"Train 표준편차: {X_num_train.std(axis=0)}\")  # 거의 1",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6s6070pylhu",
   "source": "### 5-2. 텍스트 피처 벡터화 (TF-IDF)\n\n**TF-IDF란?**\n\nTF-IDF (Term Frequency-Inverse Document Frequency)는 **텍스트를 숫자 벡터로 변환**하는 방법입니다.\n\n**공식:**\n\n$$\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)$$\n\n- **TF (Term Frequency)**: 문서 내 단어 빈도\n  - $\\text{TF}(t, d) = \\frac{\\text{단어 } t \\text{가 문서 } d \\text{에 등장한 횟수}}{\\text{문서 } d \\text{의 총 단어 수}}$\n\n- **IDF (Inverse Document Frequency)**: 단어의 희귀성\n  - $\\text{IDF}(t) = \\log\\left(\\frac{\\text{전체 문서 수}}{\\text{단어 } t \\text{가 등장한 문서 수}}\\right)$\n\n**직관적 이해:**\n\n| 단어 | TF (문서 내 빈도) | IDF (희귀성) | TF-IDF | 의미 |\n|------|------------------|--------------|--------|------|\n| \"analyze\" | 높음 | 높음 | **높음** | 이 직무에 중요! |\n| \"operate\" | 높음 | 낮음 (많은 직무에 등장) | 중간 | 흔한 단어 |\n| \"the\" | 높음 | 매우 낮음 (모든 문서 등장) | **낮음** | 의미 없음 |\n\n**왜 TF-IDF를 사용하는가?**\n\n1. **중요한 단어 강조**: \"analyze data\", \"develop software\" → 전문성 표현\n2. **불용어 제거**: \"the\", \"and\", \"or\" → 낮은 가중치\n3. **직무 특성 구별**: 복잡한 직무는 전문 용어 많음 → 높은 임금 예측\n\n### 🔧 TF-IDF 설정\n\n```python\nTfidfVectorizer(\n    max_features=100,      # 상위 100개 단어만 사용 (차원 축소)\n    stop_words='english',  # 영어 불용어 제거\n    min_df=2,              # 2개 이상 문서에 등장한 단어만\n    max_df=0.8             # 80% 이상 문서에 등장하면 제외 (너무 흔함)\n)\n```\n\n### ⚠️ 데이터 누수 방지!\n\n**올바른 순서:**\n1. Train 데이터로 TF-IDF 학습 (fit) → 어떤 단어가 중요한지 학습\n2. Train과 Test를 각각 변환 (transform)\n\n**잘못된 예:**\n```python\n# ❌ 전체 데이터로 fit하면 test 정보 누수!\ntfidf.fit(전체_descriptions)\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4ml4j9zco5",
   "source": "# 텍스트 피처 벡터화\ntfidf = TfidfVectorizer(\n    max_features=100,      # 상위 100개 중요 단어만\n    stop_words='english',  # 영어 불용어 제거\n    min_df=2,              # 최소 2개 문서에 등장\n    max_df=0.8             # 80% 이상 문서 등장 시 제외\n)\n\n# Train 데이터로 fit (어떤 단어가 중요한지 학습)\nX_text_train = tfidf.fit_transform(desc_train)\n\n# Test 데이터는 transform만 (train에서 학습한 단어만 사용)\nX_text_test = tfidf.transform(desc_test)\n\nprint(\"✅ 텍스트 벡터화 완료\")\nprint(f\"Train 텍스트 shape: {X_text_train.shape} (희소행렬)\")\nprint(f\"Test 텍스트 shape: {X_text_test.shape}\")\nprint(f\"사용된 단어 수: {len(tfidf.get_feature_names_out())}\")\nprint(f\"\\n상위 10개 중요 단어:\")\nprint(tfidf.get_feature_names_out()[:10])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5k78j7xucqk",
   "source": "### 5-3. 피처 결합 (숫자 + 텍스트)\n\n**두 가지 실험:**\n\n**실험 1: 숫자 피처만 (Baseline)**\n- AIOE + Employment_log\n- 간단하고 해석 쉬움\n- 성능 비교 기준선\n\n**실험 2: 숫자 + 텍스트 피처 결합**\n- AIOE + Employment_log + Description (TF-IDF 100개 단어)\n- 텍스트가 예측력을 높이는지 확인\n\n### 🔧 희소행렬 결합\n\n**왜 희소행렬(Sparse Matrix)인가?**\n\nTF-IDF는 대부분의 값이 0인 행렬을 생성합니다.\n\n**예시:**\n```\n직업1: [0.5, 0.0, 0.3, 0.0, 0.0, ...]  # 100개 단어 중 2개만 등장\n직업2: [0.0, 0.7, 0.0, 0.0, 0.4, ...]  # 100개 단어 중 2개만 등장\n```\n\n**메모리 효율:**\n- 일반 배열: 747 jobs × 100 words = 74,700 개 숫자 저장\n- 희소행렬: 0이 아닌 값만 저장 → **메모리 90% 절약**\n\n**결합 방법:**\n```python\n# 숫자 피처를 희소행렬로 변환\nX_num_sparse = csr_matrix(X_num_train)\n\n# 텍스트 피처 (이미 희소행렬)\nX_text_train  # TF-IDF 결과\n\n# 수평 결합 (hstack)\nX_combined = hstack([X_num_sparse, X_text_train])\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "r5e6tmbvu5",
   "source": "# 피처 결합\n# 실험 1: 숫자 피처만 (이미 준비됨)\n# X_num_train, X_num_test\n\n# 실험 2: 숫자 + 텍스트 피처 결합\nX_train_combined = hstack([\n    csr_matrix(X_num_train),  # 숫자 피처를 희소행렬로 변환\n    X_text_train              # 텍스트 피처 (이미 희소행렬)\n])\n\nX_test_combined = hstack([\n    csr_matrix(X_num_test),\n    X_text_test\n])\n\nprint(\"✅ 피처 결합 완료\")\nprint(f\"\\n실험 1 (숫자만):\")\nprint(f\"  Train: {X_num_train.shape}\")\nprint(f\"  Test: {X_num_test.shape}\")\nprint(f\"\\n실험 2 (숫자 + 텍스트):\")\nprint(f\"  Train: {X_train_combined.shape}\")\nprint(f\"  Test: {X_test_combined.shape}\")\nprint(f\"\\n피처 구성:\")\nprint(f\"  - 숫자 피처: 2개 (AIOE, Employment_log)\")\nprint(f\"  - 텍스트 피처: {X_text_train.shape[1]}개 (TF-IDF 단어)\")\nprint(f\"  - 총 피처: {X_train_combined.shape[1]}개\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "mdx8i43zlwa",
   "source": "## 6. 모델 학습 및 평가\n\n### 📊 평가 지표 설명\n\n**1. R² (R-squared, 결정계수)**\n\n$$R^2 = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}} = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$$\n\n- **의미**: 모델이 타겟 변수의 분산을 얼마나 설명하는가?\n- **범위**: 0 ~ 1 (높을수록 좋음)\n- **해석**:\n  - R² = 0.8 → 모델이 분산의 80%를 설명\n  - R² = 0.5 → 50% 설명 (나머지 50%는 설명 못함)\n  - R² = 0 → 평균값 예측과 동일\n\n**2. RMSE (Root Mean Squared Error)**\n\n$$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n\n- **의미**: 예측값과 실제값의 평균적인 차이\n- **단위**: 타겟 변수와 같은 단위 (여기서는 log 스케일)\n- **해석**:\n  - RMSE = 0.2 → 평균적으로 ±0.2 차이 (log 스케일)\n  - 낮을수록 좋음\n\n**왜 두 지표를 함께 보는가?**\n\n| 지표 | 장점 | 단점 |\n|------|------|------|\n| **R²** | 상대적 성능 비교 쉬움 | 절대적 오차 모름 |\n| **RMSE** | 실제 오차 크기 알 수 있음 | 데이터셋마다 기준 다름 |\n\n### 🧪 실험 설계\n\n**3가지 모델 × 2가지 피처 = 6개 실험**\n\n| 모델 | 특징 | 기대 성능 |\n|------|------|----------|\n| **Linear Regression** | 선형 관계 가정 | 빠르지만 단순 |\n| **Random Forest** | 비선형 OK, 앙상블 | 더 나은 성능 |\n| **LightGBM** | Gradient Boosting | 최고 성능 기대 |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205fb37",
   "metadata": {},
   "outputs": [],
   "source": "# 모델 평가 함수\ndef eval_model(name, model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    모델을 학습하고 평가하는 함수\n    \n    Parameters:\n    -----------\n    name : str\n        모델 이름 (출력용)\n    model : sklearn estimator\n        학습할 모델 객체\n    X_train, y_train : 학습 데이터\n    X_test, y_test : 테스트 데이터\n    \n    Returns:\n    --------\n    r2, rmse : float\n        R² 점수와 RMSE 값\n    \"\"\"\n    # 모델 학습\n    model.fit(X_train, y_train)\n    \n    # 예측\n    y_pred = model.predict(X_test)\n    \n    # 평가\n    r2 = r2_score(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    \n    print(f\"{name:40s} | R² = {r2:.4f} | RMSE = {rmse:.4f}\")\n    \n    return r2, rmse, y_pred"
  },
  {
   "cell_type": "markdown",
   "id": "55qfsejpg95",
   "source": "### 6-1. 실험 1: 숫자 피처만 (Baseline)\n\n**목적:**\n- AIOE와 Employment_log만으로 임금 예측 가능한가?\n- 이후 텍스트 추가 시 성능 향상 정도 측정 기준\n\n**사용 피처:**\n- `AIOE`: AI 직업 노출도 점수 (2~5)\n- `Employment_log`: 고용 규모 (로그 변환)\n\n**기대 결과:**\n- 02번 EDA에서 AIOE와 Mean_Wage의 양의 상관관계 확인\n- R² > 0.5 정도 예상 (중간 수준 예측력)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97e25d",
   "metadata": {},
   "outputs": [],
   "source": "# 실험 1: 숫자 피처만 사용\nprint(\"=\" * 80)\nprint(\"🔬 실험 1: 숫자 피처만 (AIOE + Employment_log)\")\nprint(\"=\" * 80)\n\nresults_numeric = {}\n\n# Linear Regression\nprint(\"\\n[1] Linear Regression\")\nr2, rmse, _ = eval_model(\n    \"Linear Regression (Numeric)\", \n    LinearRegression(), \n    X_num_train, y_train, X_num_test, y_test\n)\nresults_numeric['Linear Regression'] = {'R²': r2, 'RMSE': rmse}\n\n# Random Forest\nprint(\"\\n[2] Random Forest\")\nr2, rmse, _ = eval_model(\n    \"Random Forest (Numeric)\", \n    RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1), \n    X_num_train, y_train, X_num_test, y_test\n)\nresults_numeric['Random Forest'] = {'R²': r2, 'RMSE': rmse}\n\n# LightGBM\nprint(\"\\n[3] LightGBM\")\nr2, rmse, _ = eval_model(\n    \"LightGBM (Numeric)\", \n    LGBMRegressor(n_estimators=100, random_state=42, verbosity=-1), \n    X_num_train, y_train, X_num_test, y_test\n)\nresults_numeric['LightGBM'] = {'R²': r2, 'RMSE': rmse}\n\nprint(\"\\n\" + \"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "id": "bfmecwhueiv",
   "source": "### 6-2. 실험 2: 숫자 + 텍스트 피처 결합\n\n**목적:**\n- Description (직무 설명)을 추가하면 성능이 향상되는가?\n- 텍스트 정보가 임금 예측에 얼마나 기여하는가?\n\n**사용 피처:**\n- `AIOE`: AI 직업 노출도\n- `Employment_log`: 고용 규모\n- `Description (TF-IDF)`: 직무 설명 100개 단어\n\n**총 피처 수:** 2 (숫자) + 100 (텍스트) = 102개\n\n**가설:**\n- 복잡한 직무 → 전문 용어 많음 → 높은 임금\n- 단순한 직무 → 일반 용어 → 낮은 임금\n- 따라서 텍스트 추가 시 **R² 향상** 기대",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859ffec",
   "metadata": {},
   "outputs": [],
   "source": "# 실험 2: 숫자 + 텍스트 피처 결합\nprint(\"\\n\" + \"=\" * 80)\nprint(\"🔬 실험 2: 숫자 + 텍스트 피처 (AIOE + Employment_log + Description)\")\nprint(\"=\" * 80)\n\nresults_combined = {}\n\n# Linear Regression\nprint(\"\\n[1] Linear Regression\")\nr2, rmse, _ = eval_model(\n    \"Linear Regression (Combined)\", \n    LinearRegression(), \n    X_train_combined, y_train, X_test_combined, y_test\n)\nresults_combined['Linear Regression'] = {'R²': r2, 'RMSE': rmse}\n\n# Random Forest\nprint(\"\\n[2] Random Forest\")\nr2, rmse, _ = eval_model(\n    \"Random Forest (Combined)\", \n    RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1), \n    X_train_combined, y_train, X_test_combined, y_test\n)\nresults_combined['Random Forest'] = {'R²': r2, 'RMSE': rmse}\n\n# LightGBM\nprint(\"\\n[3] LightGBM\")\nr2, rmse, _ = eval_model(\n    \"LightGBM (Combined)\", \n    LGBMRegressor(n_estimators=100, random_state=42, verbosity=-1), \n    X_train_combined, y_train, X_test_combined, y_test\n)\nresults_combined['LightGBM'] = {'R²': r2, 'RMSE': rmse}\n\nprint(\"\\n\" + \"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "id": "su0bsw0mxpr",
   "source": "## 7. 결과 비교 및 해석\n\n### 📊 성능 비교표\n\n두 실험의 결과를 비교하여 다음 질문에 답합니다:\n\n**핵심 질문:**\n1. 어떤 모델이 가장 좋은 성능을 보이는가?\n2. 텍스트 피처 추가가 성능을 향상시켰는가?\n3. 얼마나 향상되었는가?\n\n**비교 기준:**\n- **R² 증가**: 설명력 향상 정도\n- **RMSE 감소**: 예측 오차 감소 정도",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a954f82",
   "metadata": {},
   "outputs": [],
   "source": "# 결과 정리\nresults_df = pd.DataFrame({\n    '숫자만 (R²)': [results_numeric[m]['R²'] for m in results_numeric],\n    '숫자만 (RMSE)': [results_numeric[m]['RMSE'] for m in results_numeric],\n    '숫자+텍스트 (R²)': [results_combined[m]['R²'] for m in results_combined],\n    '숫자+텍스트 (RMSE)': [results_combined[m]['RMSE'] for m in results_combined],\n}, index=results_numeric.keys())\n\n# R² 향상률 계산\nresults_df['R² 향상'] = results_df['숫자+텍스트 (R²)'] - results_df['숫자만 (R²)']\nresults_df['RMSE 감소'] = results_df['숫자만 (RMSE)'] - results_df['숫자+텍스트 (RMSE)']\n\nprint(\"\\n\" + \"=\" * 100)\nprint(\"📊 최종 성능 비교\")\nprint(\"=\" * 100)\nprint(results_df.round(4))\nprint(\"\\n\" + \"=\" * 100)"
  },
  {
   "cell_type": "markdown",
   "id": "txyk8m4mde",
   "source": "### 📈 성능 시각화",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6izozemvrtd",
   "source": "# R² 비교 시각화\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# R² 비교\nax1 = axes[0]\nmodels = results_df.index\nx = np.arange(len(models))\nwidth = 0.35\n\nbars1 = ax1.bar(x - width/2, results_df['숫자만 (R²)'], width, label='숫자만', alpha=0.8)\nbars2 = ax1.bar(x + width/2, results_df['숫자+텍스트 (R²)'], width, label='숫자+텍스트', alpha=0.8)\n\nax1.set_xlabel('모델')\nax1.set_ylabel('R² (높을수록 좋음)')\nax1.set_title('R² 비교')\nax1.set_xticks(x)\nax1.set_xticklabels(models, rotation=15, ha='right')\nax1.legend()\nax1.grid(axis='y', alpha=0.3)\nax1.set_ylim(0, 1)\n\n# 값 표시\nfor bars in [bars1, bars2]:\n    for bar in bars:\n        height = bar.get_height()\n        ax1.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n\n# RMSE 비교\nax2 = axes[1]\nbars3 = ax2.bar(x - width/2, results_df['숫자만 (RMSE)'], width, label='숫자만', alpha=0.8)\nbars4 = ax2.bar(x + width/2, results_df['숫자+텍스트 (RMSE)'], width, label='숫자+텍스트', alpha=0.8)\n\nax2.set_xlabel('모델')\nax2.set_ylabel('RMSE (낮을수록 좋음)')\nax2.set_title('RMSE 비교')\nax2.set_xticks(x)\nax2.set_xticklabels(models, rotation=15, ha='right')\nax2.legend()\nax2.grid(axis='y', alpha=0.3)\n\n# 값 표시\nfor bars in [bars3, bars4]:\n    for bar in bars:\n        height = bar.get_height()\n        ax2.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "k3rccgaz7b",
   "source": "### 💡 결과 해석\n\n**이 섹션은 실제 실행 후 결과를 보고 작성해야 합니다. 아래는 예상 패턴입니다.**\n\n#### 예상되는 발견사항:\n\n**1. 모델별 성능**\n- **Linear Regression**: 가장 단순한 모델, R² 0.4~0.6 예상\n  - 선형 관계만 포착\n  - 빠르지만 성능 제한적\n  \n- **Random Forest**: 비선형 관계 포착, R² 0.6~0.7 예상\n  - 의사결정나무 앙상블\n  - 과적합 위험 있음\n  \n- **LightGBM**: 최고 성능, R² 0.7~0.8 예상\n  - Gradient Boosting\n  - 복잡한 패턴 학습\n\n**2. 텍스트 피처의 효과**\n- **예상**: R² 향상 0.05~0.15\n- **의미**: Description이 추가 정보 제공\n- **해석 예시**:\n  ```\n  Linear Regression: 0.50 → 0.60 (+0.10)\n  Random Forest: 0.65 → 0.72 (+0.07)\n  LightGBM: 0.70 → 0.78 (+0.08)\n  ```\n\n**3. 실용적 의미**\n- **RMSE 0.2 = 원래 스케일로 약 $10,000~$15,000 오차**\n  - log 변환 역산: `np.expm1(0.2)` ≈ 1.22\n  - 평균 임금 $80,000일 때 → ±22% 오차\n  \n- **R² 0.7 = 임금 분산의 70% 설명**\n  - 상당히 좋은 성능\n  - 나머지 30%는 다른 요인 (지역, 산업, 경력 등)\n\n#### 실행 후 확인할 질문:\n\n1. **텍스트가 실제로 도움이 되었는가?**\n   - R² 향상 > 0.05이면 유의미\n\n2. **어떤 모델이 가장 좋은가?**\n   - R²와 RMSE 모두 고려\n\n3. **과적합은 없는가?**\n   - Train과 Test 성능 차이가 크면 과적합\n   - (이 노트북에서는 train 성능을 출력하지 않음, 필요시 추가)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "euzohpwxj39",
   "source": "## 8. 피처 중요도 분석\n\n### 🔍 Random Forest 피처 중요도\n\n**피처 중요도란?**\n- 각 피처가 예측에 얼마나 기여하는지 측정\n- Random Forest는 각 분기(split)에서 피처의 기여도를 계산\n- 높을수록 중요한 피처\n\n**왜 Random Forest를 사용하는가?**\n- Linear Regression: 계수(coefficient)만 제공, 해석 어려움\n- Random Forest: 직관적인 중요도 제공\n- LightGBM: 희소행렬 호환 문제\n\n**분석 목적:**\n1. **숫자 피처**: AIOE vs Employment_log 중 어느 것이 더 중요한가?\n2. **텍스트 피처**: 어떤 단어가 임금 예측에 중요한가?\n   - 전문성 관련 단어 (\"research\", \"develop\") → 높은 임금?\n   - 단순 업무 단어 (\"operate\", \"assist\") → 낮은 임금?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c30e6e",
   "metadata": {},
   "outputs": [],
   "source": "# Random Forest 모델 재학습 (피처 중요도 추출용)\nrf_best = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\nrf_best.fit(X_train_combined, y_train)\n\n# 피처 이름 생성\nnumeric_features = ['AIOE', 'Employment_log']\ntext_features = tfidf.get_feature_names_out().tolist()\nall_features = numeric_features + text_features\n\n# 피처 중요도 추출\nimportances = rf_best.feature_importances_\n\n# DataFrame으로 정리\nfeature_importance_df = pd.DataFrame({\n    'feature': all_features,\n    'importance': importances\n}).sort_values(by='importance', ascending=False)\n\n# 상위 20개 중요 피처 시각화\ntop_20 = feature_importance_df.head(20)\n\nplt.figure(figsize=(10, 8))\nplt.barh(range(len(top_20)), top_20['importance'], align='center')\nplt.yticks(range(len(top_20)), top_20['feature'])\nplt.xlabel('중요도 (Feature Importance)')\nplt.ylabel('피처')\nplt.title('상위 20개 중요 피처 (Random Forest)')\nplt.gca().invert_yaxis()  # 가장 중요한 피처를 위에 표시\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n📊 상위 20개 중요 피처:\")\nprint(\"=\" * 50)\nprint(top_20.to_string(index=False))\nprint(\"=\" * 50)"
  },
  {
   "cell_type": "markdown",
   "id": "b18pcaig64e",
   "source": "### 💡 피처 중요도 해석\n\n**이 섹션은 실제 실행 후 결과를 보고 작성해야 합니다. 아래는 예상 패턴입니다.**\n\n#### 예상되는 발견사항:\n\n**1. 숫자 피처의 역할**\n- **AIOE**: 중요도 높을 것으로 예상\n  - 02번 EDA에서 임금과 양의 상관관계 확인\n  - AI 노출도 높을수록 → 전문성 높음 → 높은 임금\n  \n- **Employment_log**: 중요도 중간\n  - 고용 규모와 임금의 관계는 직접적이지 않음\n  - 일부 전문직(의사, 변호사)은 소수지만 고임금\n\n**2. 텍스트 피처의 역할**\n\n예상되는 중요 단어:\n\n| 단어 유형 | 예시 | 임금과의 관계 |\n|----------|------|--------------|\n| **전문성** | \"research\", \"analyze\", \"develop\" | ↑ 높은 임금 |\n| **관리** | \"manage\", \"direct\", \"coordinate\" | ↑ 높은 임금 |\n| **기술** | \"software\", \"engineer\", \"system\" | ↑ 높은 임금 |\n| **단순 업무** | \"operate\", \"assist\", \"clean\" | ↓ 낮은 임금 |\n| **육체 노동** | \"physical\", \"manual\", \"labor\" | ↓ 낮은 임금 |\n\n**3. 실용적 해석**\n\n- **상위 1~5번 피처**: 핵심 예측 요인\n  - 대부분의 예측력은 상위 몇 개 피처에서 나옴\n  \n- **숫자 vs 텍스트 비율**:\n  - 상위 20개 중 숫자 피처 2개, 텍스트 18개 예상\n  - 텍스트가 다양한 각도에서 정보 제공\n  \n- **모델 개선 힌트**:\n  - 중요도 낮은 피처 제거 → 단순화\n  - 중요 단어 기반으로 새로운 피처 생성 가능\n\n#### 실행 후 확인할 질문:\n\n1. **AIOE가 가장 중요한 피처인가?**\n   - 그렇다면 이론과 일치\n\n2. **어떤 텍스트 단어가 중요한가?**\n   - 전문성/관리 단어 vs 단순 업무 단어\n\n3. **텍스트 피처의 총 기여도는?**\n   - 상위 20개 중 몇 개가 텍스트인가?",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "395a1yxrfkc",
   "source": "## 9. 최종 인사이트 및 결론\n\n### 🎯 핵심 발견사항\n\n**이 분석을 통해 우리는 다음을 확인했습니다:**\n\n#### 1. AIOE는 임금 예측에 유용한 지표다\n- AIOE 점수만으로도 임금의 상당 부분을 예측 가능\n- Felten et al. (2023) 논문 결과 재현 성공\n- AI 노출도가 높을수록 → 전문성 높음 → 높은 임금\n\n#### 2. 텍스트 정보는 추가 가치를 제공한다\n- Description 추가 시 성능 향상 확인\n- 직무 설명에 포함된 전문 용어가 임금 예측에 기여\n- 숫자 피처만으로 포착하지 못한 정보 보완\n\n#### 3. 복잡한 모델이 더 나은 성능을 보인다\n- Linear Regression < Random Forest < LightGBM 순서\n- 비선형 관계를 포착하는 모델이 유리\n- 하지만 해석 가능성은 trade-off\n\n---\n\n### 📚 학습 내용 정리\n\n#### 데이터 과학 기술\n\n| 단계 | 학습 내용 | 핵심 개념 |\n|------|----------|----------|\n| **전처리** | Train/Test 분할 | 데이터 누수 방지 |\n| **스케일링** | StandardScaler | 평균 0, 분산 1 변환 |\n| **텍스트 벡터화** | TF-IDF | 중요 단어 가중치 계산 |\n| **피처 결합** | 희소행렬 (sparse matrix) | 메모리 효율성 |\n| **모델 학습** | 3가지 회귀 모델 | 선형 vs 비선형 |\n| **평가** | R², RMSE | 성능 측정 지표 |\n| **해석** | 피처 중요도 | 모델 설명 가능성 |\n\n#### 머신러닝 Best Practices\n\n**✅ 올바른 방법:**\n1. **데이터 분할 먼저** → 스케일링/벡터화\n2. Train 데이터로 **fit** → Train/Test 모두 **transform**\n3. 로그 변환으로 치우친 분포 정규화\n4. 여러 모델 비교 실험\n5. 정량적(R², RMSE) + 정성적(피처 중요도) 평가\n\n**❌ 피해야 할 실수:**\n1. 전체 데이터로 스케일링 → 데이터 누수\n2. Test 데이터로 fit → 실전 불가능\n3. 단일 모델만 사용 → 비교 기준 없음\n4. 평가 지표만 보고 해석 안 함\n\n---\n\n### 🚀 향후 개선 방향\n\n**1. 더 많은 피처 추가**\n- 지역 정보 (도시별 임금 차이)\n- 산업 분류 (업종별 임금 구조)\n- 교육 요구사항 (학위, 자격증)\n\n**2. 모델 성능 향상**\n- 하이퍼파라미터 튜닝 (GridSearchCV, RandomizedSearchCV)\n- 앙상블 모델 (Stacking, Voting)\n- 교차 검증 (Cross-validation)\n\n**3. 더 깊은 분석**\n- 예측 오차가 큰 직업 분석\n- 잔차 분석 (Residual Analysis)\n- SHAP values로 개별 예측 설명\n\n**4. 실용적 활용**\n- 웹 애플리케이션 개발\n- 새로운 직업의 AIOE → 임금 예측 시스템\n- 정책 입안자를 위한 대시보드\n\n---\n\n### 📖 참고 문헌\n\n1. **Felten, E., Raj, M., & Seamans, R. (2023)**  \n   *How will Language Modelers like ChatGPT Affect Occupations and Industries?*  \n   - AIOE 계산 방법론\n   - AI 기술과 임금의 관계\n\n2. **Felten, E., Raj, M., & Seamans, R. (2021)**  \n   *Occupational, industry, and geographic exposure to artificial intelligence: A novel dataset and its potential uses*  \n   - AIOE 지표 최초 제안\n   - O*NET 기반 AI 노출도 측정\n\n3. **O*NET Database**  \n   *Occupational Information Network*  \n   - 직업별 능력 중요도 데이터\n   - 직무 설명 정보\n\n4. **BLS OEWS**  \n   *Bureau of Labor Statistics - Occupational Employment and Wage Statistics*  \n   - 고용 규모 및 임금 데이터\n\n---\n\n### 🎓 결론\n\n이 노트북에서는 **AIOE 점수와 직무 설명을 활용하여 직업의 평균 임금을 예측**하는 머신러닝 모델을 구축했습니다.\n\n**성공적으로 확인한 것:**\n- AIOE는 임금 예측에 유용한 지표\n- 텍스트 정보가 추가적인 예측력 제공\n- 복잡한 모델(LightGBM, Random Forest)이 더 나은 성능\n\n**학습한 것:**\n- 데이터 누수 방지의 중요성\n- TF-IDF 텍스트 벡터화\n- 다양한 회귀 모델 비교\n- 피처 중요도 해석\n\n**다음 단계:**\n- 실제 데이터로 실행하여 결과 확인\n- 해석 섹션에 구체적인 숫자 추가\n- 추가 피처로 성능 개선 시도\n\n---\n\n**🎉 수고하셨습니다! 이제 전체 파이프라인(전처리 → EDA → 모델링)을 완성했습니다.**",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}